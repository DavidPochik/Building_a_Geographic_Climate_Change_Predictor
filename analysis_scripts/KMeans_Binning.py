import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier
from sklearn.base import BaseEstimator, clone
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.utils.metaestimators import available_if
from sklearn.utils.validation import check_is_fitted

# load combined data file generated by gen_combined_csv.py
gsoy_df = pd.read_csv('data/combined_us48_GSOY_data.csv')

# list of features we want to regress on after this preprocessing step
features = ['TMIN', 'TMAX', 'TAVG', 'SNOW', 'PRCP', 'HTDD']

# train the clusterer on 1949 data, which we won't use in the eventual regressions
spatial_cluster_train = gsoy_df[gsoy_df['DATE']==1949]

# define an inductive clusterer where you can choose what clustering and classification algorithm you use 
# I got this from a sklearn tutorial
def _classifier_has(attr):
    """Check if we can delegate a method to the underlying classifier.

    First, we check the first fitted classifier if available, otherwise we
    check the unfitted classifier.
    """
    return lambda estimator: (
        hasattr(estimator.classifier_, attr)
        if hasattr(estimator, "classifier_")
        else hasattr(estimator.classifier, attr)
    )

class InductiveClusterer(BaseEstimator):
    def __init__(self, clusterer, classifier):
        self.clusterer = clusterer
        self.classifier = classifier

    def fit(self, X, y=None):
        self.clusterer_ = clone(self.clusterer)
        self.classifier_ = clone(self.classifier)
        y = self.clusterer_.fit_predict(X)
        self.classifier_.fit(X, y)
        return self

    @available_if(_classifier_has("predict"))
    def predict(self, X):
        check_is_fitted(self)
        return self.classifier_.predict(X)

    @available_if(_classifier_has("decision_function"))
    def decision_function(self, X):
        check_is_fitted(self)
        return self.classifier_.decision_function(X)

# define your clusterer and classifier - we're using KMeans and KNeighbors here
clusterer = KMeans(n_clusters=100, random_state=42) # using k=100, random state just ensures you get the same results each time
classifier = KNeighborsClassifier(n_neighbors=10)

# train the inductive clusterer on the 1949 longitude and latitude data
inductive_learner = InductiveClusterer(clusterer, classifier).fit(spatial_cluster_train[['LONGITUDE', 'LATITUDE']])

# tag all stations within the years used for later regression (both training and test sets) with a cluster ID
gsoy_df_reg_years = gsoy_df[gsoy_df['DATE'].between(1950,2024)].copy()
gsoy_df_reg_years['Cluster_ID'] = inductive_learner.predict(gsoy_df_reg_years[['LONGITUDE', 'LATITUDE']])

# save the coordinates of the cluster centers (i.e., the K-means centroids)
cluster_centers = inductive_learner.clusterer_.cluster_centers_

# bin and save the binned data!
binned_data_arr = []
for year in np.arange(1950,2025,1,dtype=int):
    df_in_year = gsoy_df_reg_years[gsoy_df_reg_years['DATE']==year]
    
    for cluster_id in range(100):
        cluster_lon, cluster_lat = cluster_centers[cluster_id]
        cluster_year_info = [cluster_id, year, cluster_lon, cluster_lat]
        binned_features = []
        for feature in features:
            # using nanmean because I didn't specifically drop NaNs for each feature
            mean_feature = np.nanmean(df_in_year[df_in_year['Cluster_ID']==cluster_id][feature])
            binned_features.append(mean_feature)
        binned_data_arr.append(cluster_year_info + binned_features)
        
    # for each year, plot the decision boundaries and stations in each cluster (can comment this block out if unneeded)
    # I used the stations with valid TAVG here since there are fewer of them so the plot would be (slightly) less chaotic
    # but you can use any feature!
    df_for_plot = df_in_year.dropna(subset=['TAVG'])
    fig, ax = plt.subplots(figsize=(7.5,5), constrained_layout=True)
    DecisionBoundaryDisplay.from_estimator(inductive_learner, df_for_plot[['LONGITUDE', 'LATITUDE']], response_method="predict", alpha=0.3, 
                                           plot_method='pcolormesh', cmap='tab20', xlabel='Longitude', ylabel='Latitude', ax=ax)
    ax.scatter(df_for_plot['LONGITUDE'].values, df_for_plot['LATITUDE'].values, c=df_for_plot['Cluster_ID'], 
               alpha=0.7, marker='.', edgecolor='none', cmap='tab20')
    ax.set_xlim(-126,-66)
    ax.set_ylim(23.5,50)
    fig.suptitle(year)
    fig.savefig(f'k100_binning_plots/{year}.png')
    plt.close()

# convert binned data to DataFrame and save as CSV
binned_df = pd.DataFrame(binned_data_arr, columns=['Cluster_ID', 'Year', 'Lon', 'Lat']+features)
binned_df.to_csv('data/binned_k100_1950to2024.csv', index=False)

# read in all the year-by-year cluster maps and make them a GIF (again, you can comment this out)
from PIL import Image
import glob

images = []
for fname in sorted(glob.glob('k100_binning_plots/*.png')): # loop through all png files in the folder
    im = Image.open(fname) # open the image
    images.append(im) # add the image to the list
images[0].save('k100_binning_animated.gif', save_all=True, append_images=images[1:], optimize=False, duration=500, loop=0)